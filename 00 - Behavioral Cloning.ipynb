{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n",
    "### Galen Ballew, 2017\n",
    "### Udacity SDCE ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import csv\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8036, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.14829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake     speed  \n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0  22.14829  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in driving data from simulator and add column names\n",
    "df = pd.read_csv('driving_log.csv', names=['center', 'left', 'right', 'steering_angle',\n",
    "                                               'throttle', 'brake', 'speed'], header=None)\n",
    "#precision of values is 7 digits\n",
    "# 25,781 observations, 6 features, 1 target\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEeCAYAAAA5CErsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X9UVHd+//HnfEe3VVCG4gz+QNwYCESCIVFB3ciKGgnF\nhBh1IZvjaUgpxuiu0gSNa1rUTUv8EX/shqANmKRGTzeiTUJLTOOKv1HcnpgxalmSrKwhLiDrKBBR\ngvP9o/XuTvwBKANcfD3O4Y+5931nPvcz9/jy8/ncCxaXy+VGRETEBP5fZzdARESktRRaIiJiGgot\nERExDYWWiIiYhkJLRERMQ6ElIiKmodAS6WY2b96MzWZj8+bNnd0UkXan0BJpg8TERGw2GxUVFZ3d\nFJE7Uo/OboCItK8pU6YwatQoAgMDO7spIu1OoSXSzfj5+eHn59fZzRDxCk0PivyfDz/8kKSkJMLD\nw3E4HISFhREfH8+rr74KgM1m48CBAwDcf//92Gw2bDYbkZGRHu9z/vx5/umf/okxY8YwYMAAgoKC\neOSRR3jvvfdu+Nl79+4lJSWFu+++G7vdzn333cfzzz9PVVXVNbVXpyhPnTpFbm4uY8aMITAwkB//\n+MfAjde0IiMjsdlsfPvtt7z66qs8+OCDOBwOIiIiyMrK4vLly9dt27vvvktsbCz9+/cnJCSE9PR0\nzpw5Y7RDpCNppCUCvPXWW8yfPx+Hw0F8fDx2u53a2lrKysp48803ef7551m4cCFbtmzh9OnTPPvs\ns8Zo5s9HNV9//TWPPvooX3zxBWPGjOHpp5/mm2++4b/+6794+umnWbhwIYsWLfL47LVr17JkyRL8\n/f2ZPHkygYGBHD9+nPz8fD788EM+/vhjBg0adE2bFy5cyKFDh4iPj2fy5Mn4+vq26lzT0tIoKSlh\n0qRJ9OnTh48//ph169ZRU1PD66+/7lG7bt06srKy8PPzIyUlBT8/P4qLi4mPj6dv375t7WaR22bR\nL8wVgR/+8IecPHmSzz77DIfD4bGvtraWgIAA4H9HOQcOHODTTz9lyJAh17xPUlISe/fu5Y033mD6\n9OnG9gsXLjBlyhSOHTvG3r17jdHZgQMHmDJlCiNHjmTr1q0eI5d/+7d/49lnn+XRRx9l06ZNxvar\nbRgwYAA7duy4ph2bN29mzpw55OTk8NRTTxnbIyMjOX36NPfffz/vvfce/v7+ADQ0NPDQQw9RUVHB\nyZMnjbWwU6dOMXLkSPr06cOePXsIDg4GwO12k5aWxrZt2wBwuVxt7G2RW6fpQZH/06NHD3r27HnN\n9quB1ZLjx4+zZ88eEhMTPQILoG/fvrz44ou43W62bt1qbF+/fj1ut5s1a9ZcM9WWkpLC8OHDKSoq\noq6u7prP++lPf3rd4GzJ0qVLjcAC8PHxYcaMGVy5coVPPvnE2L5161a+/fZb0tLSjMACsFgsZGVl\nYbVa2/zZIrdL04MiwIwZM3jppZeIiYlh6tSpjB07lpiYGPr379/q9zh8+DAAdXV1ZGdnX7O/trYW\ngLKyMo9jevToQWFhIYWFhdccc/nyZZqbm/niiy+Iiory2DdixIhWt+3Pffd9AIKCggDPUZPT6QRg\nzJgx19QHBwczaNAgfv/7399SG0RulUJLBJg7dy52u52NGzeSl5fHhg0bABg1ahT/+I//yLhx41p8\njz/+8Y8A7Nmzhz179tywrqGhweOYb7/9luXLl9/0vevr66/Z9t1pzNa63s0TV0dNzc3NxrYLFy4A\nYLfbr/s+DodDoSUdTqEl8n+Sk5NJTk7mwoUL/OY3v+HDDz/k7bffZsaMGezfv5+QkJCbHn/1xoSX\nX36ZuXPntuoz+/btS1NTE6dPn25zey0WS5uPaYs+ffoAUFNTc9391dXVXv18kevRmpbId/Tt25cJ\nEyawcuVK5s6dS2NjIx9//DHwpxHJlStXrjkuOjoagJKSklZ/1qhRo6irq+PYsWPt0PL2NXz4cOD6\n5/P73/+eysrKjm6SiEJLBP53Ss/tvvZG2qvPSfXu3RuAv/qrvwK47sgoKiqKH/zgBxQVFfH2229f\n9/0+//xzj2PnzJkDwPz5868bAo2NjW0KwfY0Y8YMevToQV5ensc0oNvtZtmyZR5TiSIdRdODIsDM\nmTPx8fFh5MiRBAcHY7FY+O///m9KSkq46667ePzxxwGIi4vjvffeY968eTz22GP4+vri5+dHeno6\nAHl5eSQlJTFv3jw2bNjAqFGj8Pf35+uvv+Z//ud/cDqdvPPOOwwePBiA2NhYfv7zn5OVlcWIESN4\n+OGH+f73v09jYyOnT5/m4MGDBAcHs3///g7vk7vuuouf/exnLFu2jHHjxvHEE08Yz2mdO3eO++67\nj+PHj3d4u+TOptASAZYsWcKuXbs4duwYv/71r+nRowdBQUEsXLiQWbNmGQ8Qz5w5k6+++oqCggJe\nf/11mpqaGDx4sBFaAwYMoLi4mDfeeIP333+fbdu20dTUhMPhICQkhOXLl/PQQw95fPZPfvITRo8e\nzfr16ykpKWHHjh34+voyYMAAfvSjHzF16tQO74+r/v7v/56BAweSk5PDli1b8PX1ZeLEiSxdupQn\nnnjCWPcS6Sh6uFhE2uzChQvcc889REZGGut9Ih1Ba1oickO1tbU0NTV5bPv222956aWXaGxsZMqU\nKZ3UMrlTaXpQRG7oP//zP1m2bBnjx49n0KBBnDt3joMHD/L5558TGRlpTIuKdBSFlojc0AMPPMCY\nMWM4ePCg8fD0kCFDeOGFF5g3bx69evXq5BbKnUZrWiIiYhpa0xIREdNQaImIiGkotERExDS6ZWiV\nl5d3dhO6NfWvd6l/vUv9613e7t9uGVoiItI9KbRERMQ0FFoiImIaCi0RETGNFkMrOzsbm83m8XPP\nPfcY+91uN9nZ2YSHh9O/f38SExM5efKkx3tcunSJzMxMhg4dysCBA0lJSbnmbwe5XC7S09MJDg4m\nODiY9PR0XC5XO52miIh0B60aaYWGhlJWVmb8HDx40Ni3bt06cnJyWL58Obt27cJutzN16lTq6uqM\nmkWLFlFYWEh+fj5FRUXU1dWRnJzs8Ufk0tLScDqdFBQUUFBQgNPpZNasWe14qiIiYnat+t2DPXr0\nIDAw8Jrtbreb3Nxc5s+fT1JSEgC5ubmEhoZSUFBAamoq58+fZ9OmTeTk5BAXFwfAhg0biIyMZPfu\n3UycOJGysjJ27tzJjh07jD9ZvmbNGhISEigvLyc0NLS9zldEREysVSOtU6dOER4ezvDhw3nmmWc4\ndeoUABUVFVRVVTFhwgSjtlevXowdO5bDhw8DcPToUZqamjxqgoKCCAsLM2pKS0vx9fUlJibGqBk9\nejQ+Pj5GjYiISIsjrZEjR/L6668TGhrK2bNnWblyJZMnT+bQoUNUVVUBYLfbPY6x2+2cOXMGgOrq\naqxWKwEBAdfUVFdXGzUBAQFYLBZjv8VioV+/fkbNjdzoQTY9QOhd6t/2NWp/7z971Rv2V96w9nqO\nPPRN+zaom9P16123078tzay1GFoPP/ywx+tRo0Zx//33s2XLFkaNGnXLDWsv1ztBTSl6l/rXC9oY\nUt+l76P1dP16l7f7t823vPv4+BAeHs6XX35prHPV1NR41NTU1OBwOABwOBw0NzdTW1t705ra2lrc\n7j/9lRS3283Zs2eNGhERkTaHVmNjI+Xl5QQGBjJkyBACAwMpLi722F9SUmKsT0VFRdGzZ0+PmsrK\nSsrKyoya6Oho6uvrKS0tNWpKS0tpaGjwWOcSEZE7W4vTgy+99BKPPPIIQUFBxprWN998w5NPPonF\nYmH27NmsXr2a0NBQQkJCWLVqFT4+PkyfPh0APz8/Zs6cSVZWFna7HX9/fxYvXkxERATjx48HICws\njEmTJpGRkcHatWsByMjIID4+XsN4ERExtBhaX3/9NWlpadTW1tKvXz9GjhzJxx9/THBwMADz5s3j\n4sWLZGZm4nK5GDFiBNu3b6dPnz7Ge2RnZ2O1WklNTaWxsZHY2FjWr1+P1Wo1avLy8liwYAHTpk0D\nICEhgRUrVrT3+YqIiIlZXC6Xu+Uyc9FCq3epf9uf7c3buxHDlTqonVrS/en69a4udyOGiIhIZ1Fo\niYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmodASERHTUGiJiIhpKLRERMQ0\nFFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRER\nMQ2FloiImIZCS0RETEOhJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJL\nRERMQ6ElIiKmodASERHTaHNorV69GpvNRmZmprHN7XaTnZ1NeHg4/fv3JzExkZMnT3ocd+nSJTIz\nMxk6dCgDBw4kJSWFyspKjxqXy0V6ejrBwcEEBweTnp6Oy+W6xVMTEZHupk2hdeTIEd566y0iIiI8\ntq9bt46cnByWL1/Orl27sNvtTJ06lbq6OqNm0aJFFBYWkp+fT1FREXV1dSQnJ9Pc3GzUpKWl4XQ6\nKSgooKCgAKfTyaxZs27zFEVEpLtodWidP3+ev/u7v+O1117DZrMZ291uN7m5ucyfP5+kpCSGDRtG\nbm4u9fX1FBQUGMdu2rSJZcuWERcXR1RUFBs2bOD48ePs3r0bgLKyMnbu3MnatWuJjo4mOjqaNWvW\n8NFHH1FeXt6+Zy0iIqbU6tC6GkqxsbEe2ysqKqiqqmLChAnGtl69ejF27FgOHz4MwNGjR2lqavKo\nCQoKIiwszKgpLS3F19eXmJgYo2b06NH4+PgYNSIicmfr0Zqit99+my+//JJ/+Zd/uWZfVVUVAHa7\n3WO73W7nzJkzAFRXV2O1WgkICLimprq62qgJCAjAYrEY+y0WC/369TNqRETkztZiaJWXl7Ns2TJ2\n7NhBz549O6JNbXKjqUNNKXqX+re99b6to/V9tI36y7tup39DQ0Nvur/F0CotLaW2tpbRo0cb25qb\nmzl48CAbN27k0KFDANTU1DB48GCjpqamBofDAYDD4aC5uZna2lr69evnUTNmzBijpra2FrfbbYy2\n3G43Z8+eNd6ntSdYXl7e4onLrVP/esH+ypZrbkLfR+vp+vUub/dvi2taiYmJHDx4kH379hk/Dzzw\nANOmTWPfvn2EhIQQGBhIcXGxcUxjYyMlJSXG+lRUVBQ9e/b0qKmsrKSsrMyoiY6Opr6+ntLSUqOm\ntLSUhoYGj3UuERG5c7U40rLZbB53CwL07t0bf39/hg0bBsDs2bNZvXo1oaGhhISEsGrVKnx8fJg+\nfToAfn5+zJw5k6ysLOx2O/7+/ixevJiIiAjGjx8PQFhYGJMmTSIjI4O1a9cCkJGRQXx8vP5XJCIi\nQCtvxGjJvHnzuHjxIpmZmbhcLkaMGMH27dvp06ePUZOdnY3VaiU1NZXGxkZiY2NZv349VqvVqMnL\ny2PBggVMmzYNgISEBFasWNEeTRQRkW7A4nK53J3diPamOWvvUv+2P9ubt7em5Uod1E4t6f50/XpX\np69piYiIdBUKLRERMQ2FloiImIZCS0RETEOhJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgot\nERExDYWWiIiYhkJLRERMQ6ElIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiG\nQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIi\npqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExjRZD64033mDs2LEMHjyYwYMH8/DDD/PRRx8Z\n+91uN9nZ2YSHh9O/f38SExM5efKkx3tcunSJzMxMhg4dysCBA0lJSaGystKjxuVykZ6eTnBwMMHB\nwaSnp+NyudrpNEVEpDtoMbQGDhzI0qVL2bNnD8XFxcTGxvLUU0/x2WefAbBu3TpycnJYvnw5u3bt\nwm63M3XqVOrq6oz3WLRoEYWFheTn51NUVERdXR3Jyck0NzcbNWlpaTidTgoKCigoKMDpdDJr1iwv\nnLKIiJhVi6GVmJjIww8/zNChQwkJCeEf/uEf8PX15ciRI7jdbnJzc5k/fz5JSUkMGzaM3Nxc6uvr\nKSgoAOD8+fNs2rSJZcuWERcXR1RUFBs2bOD48ePs3r0bgLKyMnbu3MnatWuJjo4mOjqaNWvW8NFH\nH1FeXu7VDhAREfNo05pWc3Mz27Zto6GhgejoaCoqKqiqqmLChAlGTa9evRg7diyHDx8G4OjRozQ1\nNXnUBAUFERYWZtSUlpbi6+tLTEyMUTN69Gh8fHyMGhERkR6tKTp+/DiTJ0+msbERHx8f3nnnHSIi\nIoxAsdvtHvV2u50zZ84AUF1djdVqJSAg4Jqa6upqoyYgIACLxWLst1gs9OvXz6i5kRuNxDRC8y71\nb3vrfVtH6/toG/WXd91O/4aGht50f6tCKzQ0lH379nHhwgXef/99Zs+ezX/8x3/ccqPa0/VOsLy8\nvMUTl1un/vWC/ZUt19yEvo/W0/XrXd7u31ZND37ve99j6NChREVFkZWVRWRkJK+//jqBgYEA1NTU\neNTX1NTgcDgAcDgcNDc3U1tbe9Oa2tpa3G63sd/tdnP27FmjRkRE5Jae07py5QqXL19myJAhBAYG\nUlxcbOxrbGykpKTEWJ+KioqiZ8+eHjWVlZWUlZUZNdHR0dTX11NaWmrUlJaW0tDQ4LHOJSIid7YW\npweXLFnC5MmTGTRokHFX4P79+3n33XexWCzMnj2b1atXExoaSkhICKtWrcLHx4fp06cD4Ofnx8yZ\nM8nKysJut+Pv78/ixYuJiIhg/PjxAISFhTFp0iQyMjJYu3YtABkZGcTHx2sYLyIihhZDq6qqivT0\ndKqrq+nbty8REREUFBQwceJEAObNm8fFixfJzMzE5XIxYsQItm/fTp8+fYz3yM7Oxmq1kpqaSmNj\nI7Gxsaxfvx6r1WrU5OXlsWDBAqZNmwZAQkICK1asaO/zFRERE7O4XC53y2XmooVW71L/tj/bm7d3\nI4YrdVA7taT70/XrXV3iRgwREZGuQKElIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETEN\nhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RE\nTEOhJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmodAS\nERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktEREyjxdBavXo1cXFxDB48mLvvvpvk\n5GROnDjhUeN2u8nOziY8PJz+/fuTmJjIyZMnPWouXbpEZmYmQ4cOZeDAgaSkpFBZWelR43K5SE9P\nJzg4mODgYNLT03G5XO1wmiIi0h20GFr79+/nb//2b/noo4/44IMP6NGjB48//jjnzp0zatatW0dO\nTg7Lly9n165d2O12pk6dSl1dnVGzaNEiCgsLyc/Pp6ioiLq6OpKTk2lubjZq0tLScDqdFBQUUFBQ\ngNPpZNasWe18yiIiYlY9WirYvn27x+sNGzYQHBzMoUOHSEhIwO12k5uby/z580lKSgIgNzeX0NBQ\nCgoKSE1N5fz582zatImcnBzi4uKM94mMjGT37t1MnDiRsrIydu7cyY4dO4iOjgZgzZo1JCQkUF5e\nTmhoaHufu4iImEyb17Tq6+u5cuUKNpsNgIqKCqqqqpgwYYJR06tXL8aOHcvhw4cBOHr0KE1NTR41\nQUFBhIWFGTWlpaX4+voSExNj1IwePRofHx+jRkRE7mwtjrS+68UXXyQyMtIYDVVVVQFgt9s96ux2\nO2fOnAGguroaq9VKQEDANTXV1dVGTUBAABaLxdhvsVjo16+fUXM95eXlbdou7UP9295639bR+j7a\nRv3lXbfTvy3NqrUptH72s59x6NAhduzYgdVqveVGtafrnaCmE71L/esF+ytbrrkJfR+tp+vXu7zd\nv62eHly0aBHbtm3jgw8+4Pvf/76xPTAwEICamhqP+pqaGhwOBwAOh4Pm5mZqa2tvWlNbW4vb7Tb2\nu91uzp49a9SIiMidrVWhtXDhQiOw7rnnHo99Q4YMITAwkOLiYmNbY2MjJSUlxvpUVFQUPXv29Kip\nrKykrKzMqImOjqa+vp7S0lKjprS0lIaGBo91LhERuXO1OD34wgsv8Ktf/Yp33nkHm81mrGH5+Pjg\n6+uLxWJh9uzZrF69mtDQUEJCQli1ahU+Pj5Mnz4dAD8/P2bOnElWVhZ2ux1/f38WL15MREQE48eP\nByAsLIxJkyaRkZHB2rVrAcjIyCA+Pl5DeRERAVoRWnl5eQDG7exXLVy4kEWLFgEwb948Ll68SGZm\nJi6XixEjRrB9+3b69Olj1GdnZ2O1WklNTaWxsZHY2FjWr1/vsTaWl5fHggULmDZtGgAJCQmsWLHi\n9s9SRES6BYvL5XK3XGYuWmj1LvVv+7O9eXs3YrhSB7VTS7o/Xb/e1WVuxBAREelsCi0RETENhZaI\niJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOh\nJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmodASERHT\nUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERE\nxDQUWiIiYhoKLRERMY1WhdaBAwdISUnh3nvvxWazsXnzZo/9breb7OxswsPD6d+/P4mJiZw8edKj\n5tKlS2RmZjJ06FAGDhxISkoKlZWVHjUul4v09HSCg4MJDg4mPT0dl8t1m6coIiLdRatCq6GhgWHD\nhvHKK6/Qq1eva/avW7eOnJwcli9fzq5du7Db7UydOpW6ujqjZtGiRRQWFpKfn09RURF1dXUkJyfT\n3Nxs1KSlpeF0OikoKKCgoACn08msWbPa4TRFRKQ76NGaosmTJzN58mQAnnvuOY99breb3Nxc5s+f\nT1JSEgC5ubmEhoZSUFBAamoq58+fZ9OmTeTk5BAXFwfAhg0biIyMZPfu3UycOJGysjJ27tzJjh07\niI6OBmDNmjUkJCRQXl5OaGhou520iIiY022vaVVUVFBVVcWECROMbb169WLs2LEcPnwYgKNHj9LU\n1ORRExQURFhYmFFTWlqKr68vMTExRs3o0aPx8fExakRE5M7WqpHWzVRVVQFgt9s9ttvtds6cOQNA\ndXU1VquVgICAa2qqq6uNmoCAACwWi7HfYrHQr18/o+Z6ysvL27Rd2of6t731vq2j9X20jfrLu26n\nf1uaVbvt0Ops1ztBTSd6l/rXC/ZXtlxzE/o+Wk/Xr3d5u39ve3owMDAQgJqaGo/tNTU1OBwOABwO\nB83NzdTW1t60pra2Frfbbex3u92cPXvWqBERkTvbbYfWkCFDCAwMpLi42NjW2NhISUmJsT4VFRVF\nz549PWoqKyspKyszaqKjo6mvr6e0tNSoKS0tpaGhwWOdS0RE7lytmh6sr6/nyy+/BODKlSt89dVX\nOJ1O/P39GTx4MLNnz2b16tWEhoYSEhLCqlWr8PHxYfr06QD4+fkxc+ZMsrKysNvt+Pv7s3jxYiIi\nIhg/fjwAYWFhTJo0iYyMDNauXQtARkYG8fHxGsqLiAjQytD65JNPePTRR43X2dnZZGdn8+STT5Kb\nm8u8efO4ePEimZmZuFwuRowYwfbt2+nTp4/HMVarldTUVBobG4mNjWX9+vVYrVajJi8vjwULFjBt\n2jQAEhISWLFiRXudq4iImJzF5XK5Wy4zFy20epf6t/3Z3ry9GzFcqYPaqSXdn65f7+ryN2KIiIh0\nFIWWiIiYhkJLRERMQ6ElIiKmYfrfiCHSFdzujRQi0joaaYmIiGkotERExDQUWiIiYhpa0xLpBtpj\nTU0PKIsZaKQlIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDDxfL\nHU+/7FbEPDTSEhER01BoiYiIaWh6UESA258m1e8ulI6gkZaIiJiGQktERExDoSUiIqah0BIREdNQ\naImIiGno7kExPT0cLHLn0EhLRERMQ6ElIiKmoelBEWkXejhZOoJGWiIiYhoKLRERMQ1ND0qn091/\nItJaXTK08vLy+MUvfkFVVRXh4eFkZ2czduzYzm6WiHiR1sSkNbpcaG3fvp0XX3yRV199ldGjR5OX\nl8eMGTM4dOgQgwcP7uzmyXVopCQiHaXLrWnl5OTw4x//mL/5m78hLCyMlStXEhgYyMaNGzu7aSIi\n0sksLpfL3dmNuOry5csMGDCA/Px8Hn/8cWP7Cy+8wIkTJygqKurE1omISGfrUiOt2tpampubsdvt\nHtvtdjvV1dWd1CoREekqulRoiYiI3EyXCq2AgACsVis1NTUe22tqanA4HJ3UKhER6Sq6VGh973vf\nIyoqiuLiYo/txcXFxMTEdFKrRESkq+hyt7zPmTOHWbNmMWLECGJiYti4cSN/+MMfSE1N7eymiYhI\nJ+tSIy2AJ554guzsbFauXMm4ceM4dOgQ7777LsHBwTc85q233mLKlCkEBwdjs9moqKho1We9//77\nxMTE4HA4iImJobCwsL1Oo1u5dOkSmZmZDB06lIEDB5KSkkJl5c2fzdq8eTM2m+2an8bGxg5qddeV\nl5fH8OHDCQwM5Ic//CEHDx68af3x48f567/+a/r378+9997L8uXLcbu7zE2/XU5b+reiouK61+nO\nnTs7sMXmcODAAVJSUrj33nux2Wxs3ry5xWO8ce12udACSEtL49ixY1RXV7Nnzx5+8IMf3LT+m2++\nYcKECbz44out/ozS0lKeeeYZZsyYwb59+5gxYwZPP/00v/nNb263+d3OokWLKCwsJD8/n6KiIurq\n6khOTqa1OoBZAAAFeUlEQVS5ufmmx/Xu3ZuysjKPn7/8y7/soFZ3TVcfnn/++efZu3cv0dHRzJgx\ng9OnT1+3/sKFC0ydOhWHw8GuXbt45ZVX+OUvf8lrr73WwS03h7b271Xbtm3zuE5jY2M7qMXm0dDQ\nwLBhw3jllVfo1atXi/Xeuna71HNat+uTTz4hLi6OTz/9lCFDhty0NjU1lXPnzvHee+8Z25KSkujX\nrx/5+fnebqppnD9/npCQEHJycvjRj34EwFdffUVkZCQFBQVMnDjxusdt3ryZBQsWtDgiu9NMnDiR\niIgIfvGLXxjbHnzwQZKSksjKyrqmPj8/nyVLlvDb3/7W+Idi5cqVbNy4kRMnTmCxWDqs7WbQ1v6t\nqKjg/vvvp7i4mAceeKAjm2pqgwYNYsWKFTz11FM3rPHWtdslR1od4ciRI0yYMMFj28SJEzl8+HAn\ntahrOnr0KE1NTR59FRQURFhYWIt9dfHiRe677z6GDRtGcnIyn376qbeb26VdvnyZo0ePXnPdTZgw\n4YZ9WVpaypgxYzz+Zztx4kTOnDnT6mnwO8Wt9O9VM2fOJCQkhPj4eN5//31vNvOO4a1r944Nraqq\nKj3E3ArV1dVYrVYCAgI8trfUV6Ghobz22mts2bKFvLw8/uIv/oJHHnmEL774wttN7rJu5eH56urq\n69Zf3Sd/civ96+vry89//nPefPNNtm7dSmxsLKmpqfzqV7/qiCZ3a966drvc3YNXvfzyy6xateqm\nNYWFhYwbN66DWtS9tLZ/b1V0dDTR0dHG65iYGMaNG8eGDRtYsWLFLb+vSHsKCAjgJz/5ifH6gQce\n4Ny5c6xbt47k5ORObJncSJcNrdmzZxtrKDcSFBR0y+8fGBh4Rz/E3Nr+PXLkCM3NzdTW1tKvXz9j\nX01NDWPGjGn151mtVqKiovjyyy9vuc1mdysPzzscjuvWX90nf9Jev5zgwQcf5J133mnv5t1xvHXt\ndtnQCggIuGZKqj2NGjWK4uJifvrTnxrb7qSHmFvbv1FRUfTs2ZPi4mJmzJgBQGVlJWVlZW3qK7fb\nzWeffUZkZOQtt9ns/vzh+T//hdDFxcU89thj1z0mOjqaJUuW0NjYaNx5WVxczIABA1q82ehOcyv9\nez3Hjh0jMDDQG028o3jr2u0Wa1pVVVU4nU4+//xzAMrKynA6nZw7d86oeeyxx1i6dKnx+tlnn2Xv\n3r2sWbOG3/72t6xevZp9+/Yxe/bsDm9/V+bn58fMmTPJyspi9+7dfPrpp8yaNYuIiAjGjx9v1H23\nf1955RV+/etfc+rUKZxOJ3PnzuXEiRM888wznXAWXcecOXPYsmUL//qv/0pZWRkLFy70eHh+6dKl\nHv/ATp8+nV69evHcc89x4sQJPvjgA9auXctzzz2nOwevo639u2XLFrZu3UpZWRnl5eX88pe/JC8v\nj/T09M46hS6rvr4ep9OJ0+nkypUrfPXVVzidTuNxgo66drvsSKstNm7cyPLly43XV6e9cnJyjFsy\nf/e73zFo0J/+sunV37bx8ssv88///M/cddddbNy4kZEjR3Zs400gOzsbq9VKamoqjY2NxMbGsn79\neqxWq1Hz3f49f/488+bNo7q6mr59+zJ8+HCKiooYMWJEZ5xCl/HEE0/wxz/+kZUrV1JVVcW9997r\n8fD8H/7wB373u98Z9X5+fvz7v/87L7zwAnFxcdhsNubMmcPcuXM76xS6tLb2L8CqVas4ffo0VquV\nu+++m9dee03rWdfxySef8Oijjxqvs7Ozyc7O5sknnyQ3N7fDrt1u9ZyWiIh0b91ielBERO4MCi0R\nETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhr/H84qBQwGFAZrAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1768622ec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check distribution of target variable. Gaussian is better. we can see below it has very high kurtosis\n",
    "df.hist('steering_angle', bins=21);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is, there is an excess of steering angles that are very close to neutral. The model will pick up on this and will learn to steer neutral the large majority of the time. Some data augmentation may be needed to make this distribution closer to normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import pickle\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'driving_log.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cf431165347e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driving_log.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'driving_log.csv'"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "\n",
    "with open('driving_log.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    for line in reader:\n",
    "        if abs(float(line[3])) > 0.05:\n",
    "            samples.append(line)\n",
    "        else:\n",
    "            fifty = np.random.random()\n",
    "            if fifty >= 0.7:\n",
    "                samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffles automatically\n",
    "train_samples, test_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation:\n",
    "In the current pipeline, the only data augmentation I'll be doing is cropping and normalization of the pixel data. There are some other possibilities however:\n",
    "\n",
    "1) Edge detection  \n",
    "2) Different color space(s)  \n",
    "3) Adding lane offset feature by combining from Adv Lane Detection and Vehicle tracking    \n",
    "4) Resizing images\n",
    "\n",
    "#### Bootstrapping:  \n",
    "Inside of `frame_generator()` I am flipping images and the measurements. This results in x2 as many training observations. There could also be additional bootstrapping of the data:\n",
    "\n",
    "1) Perspective transform to birdseye view  \n",
    "2) Slight, random skews and warps of images  \n",
    "3) Random shadows added  \n",
    "\n",
    "If these approaches where to be taken, it may serve to have multiple models with the final output being an ensemble method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters for data (i.e. not DNN HPs)**:  \n",
    "angle correction - located inside of frame_generator  \n",
    "image cropping - located inside of model.Cropping2D  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_generator(samples, batch_size=1):\n",
    "    num_samples = len(samples)\n",
    "    while True:\n",
    "        for step_size in range(0, num_samples, batch_size):\n",
    "            batch = samples[step_size:step_size+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            \n",
    "            for observation in batch:\n",
    "                #angle correction is tuneable\n",
    "                for camera, angle_correct in zip([0, 1, 2],[0, 0.1, -0.1]):\n",
    "                    name = 'img/'+ observation[camera].split('/')[-1]\n",
    "                    #convert to HSV and extract S channel, resize by factor of 10\n",
    "                    image = cv2.resize((cv2.cvtColor(plt.imread(name), cv2.COLOR_RGB2HSV)),(32,16))[:,:,1]\n",
    "                    angle = float(observation[3]) + angle_correct\n",
    "                    #only train on Saturation\n",
    "                    images.append(image)\n",
    "                    angles.append(angle)\n",
    "            \n",
    "                X_train_orig = np.array(images)\n",
    "                y_train_orig = np.array(angles)\n",
    "\n",
    "                # create flipped image data as well\n",
    "                X_train_flip = np.array(np.fliplr(images))\n",
    "                y_train_flip =-np.array(angles)\n",
    "                \n",
    "                #resize so to add channel dimension\n",
    "                X_train_orig = X_train_orig.reshape(X_train_orig.shape[0], 16, 32, 1)\n",
    "                X_train_flip = X_train_flip.reshape(X_train_flip.shape[0], 16, 32, 1)\n",
    "\n",
    "                X_train = np.concatenate((X_train_orig, X_train_flip), axis=0)\n",
    "                y_train = np.concatenate((y_train_orig, y_train_flip), axis=0)\n",
    "\n",
    "                yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9af12a519cc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_samples' is not defined"
     ]
    }
   ],
   "source": [
    "train_gen = frame_generator(train_samples)\n",
    "test_gen = frame_generator(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally I trained a fully featured CNN with original image sizes. It took hours to train and the performance was nothing to call home about. I needed to speed up my training time and improve performance. This meant fewer parameters in the network. To do this, the first step was to make the images smaller, which is done during the generator. Next, I implemented a smaller network structure. This architecture was created by Mengxi Wu and can be found [here](https://medium.com/@xslittlegrass/self-driving-car-in-a-simulator-with-a-tiny-neural-network-13d33b871234).\n",
    "\n",
    "This new architure allowed me to train the entire network in just a few minutes instead of an entire work day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0, input_shape=(16,32,1)))\n",
    "model.add(Conv2D(12, 3, strides=3, activation='relu'))\n",
    "model.add(MaxPooling2D((4,4),(4,4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 16, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 10, 12)         120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 2, 12)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 2, 12)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
    "\n",
    "callbacks_list = []\n",
    "filepath=\"checkpoints/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=0, verbose=0, mode='auto')\n",
    "callbacks_list.append(checkpoint)\n",
    "#callbacks_list.append(early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1664/1671 [============================>.] - ETA: 0s - loss: 0.3314Epoch 00000: val_loss improved from inf to 0.30731, saving model to checkpoints/weights-improvement-00-0.31.hdf5\n",
      "1671/1671 [==============================] - 13s - loss: 0.3309 - val_loss: 0.3073\n",
      "Epoch 2/20\n",
      "1668/1671 [============================>.] - ETA: 0s - loss: 0.3223Epoch 00001: val_loss improved from 0.30731 to 0.30240, saving model to checkpoints/weights-improvement-01-0.30.hdf5\n",
      "1671/1671 [==============================] - 12s - loss: 0.3219 - val_loss: 0.3024\n",
      "Epoch 3/20\n",
      "1666/1671 [============================>.] - ETA: 0s - loss: 0.3163Epoch 00002: val_loss improved from 0.30240 to 0.29896, saving model to checkpoints/weights-improvement-02-0.30.hdf5\n",
      "1671/1671 [==============================] - 12s - loss: 0.3160 - val_loss: 0.2990\n",
      "Epoch 4/20\n",
      "1666/1671 [============================>.] - ETA: 0s - loss: 0.3128Epoch 00003: val_loss improved from 0.29896 to 0.29625, saving model to checkpoints/weights-improvement-03-0.30.hdf5\n",
      "1671/1671 [==============================] - 12s - loss: 0.3125 - val_loss: 0.2962\n",
      "Epoch 5/20\n",
      "1663/1671 [============================>.] - ETA: 0s - loss: 0.3101Epoch 00004: val_loss improved from 0.29625 to 0.29401, saving model to checkpoints/weights-improvement-04-0.29.hdf5\n",
      "1671/1671 [==============================] - 12s - loss: 0.3094 - val_loss: 0.2940\n",
      "Epoch 6/20\n",
      "1664/1671 [============================>.] - ETA: 0s - loss: 0.3071Epoch 00005: val_loss improved from 0.29401 to 0.29196, saving model to checkpoints/weights-improvement-05-0.29.hdf5\n",
      "1671/1671 [==============================] - 12s - loss: 0.3066 - val_loss: 0.2920\n",
      "Epoch 7/20\n",
      "1667/1671 [============================>.] - ETA: 0s - loss: 0.3054Epoch 00006: val_loss improved from 0.29196 to 0.29016, saving model to checkpoints/weights-improvement-06-0.29.hdf5\n",
      "1671/1671 [==============================] - 13s - loss: 0.3053 - val_loss: 0.2902\n",
      "Epoch 8/20\n",
      " 902/1671 [===============>..............] - ETA: 5s - loss: 0.3003"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-377a973cf7da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit_generator(generator=train_gen, steps_per_epoch=len(train_samples), validation_data=test_gen,\n\u001b[1;32m----> 2\u001b[1;33m                               validation_steps= len(test_samples), epochs=20, callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1844\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m                             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_gen, steps_per_epoch=len(train_samples), validation_data=test_gen,\n",
    "                              validation_steps= len(test_samples), epochs=20, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'x-')\n",
    "plt.plot(history.history['val_loss'],'o-')\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255 - 0.5, input_shape=(160,320,3)))\n",
    "#amount of cropping is tuneable\n",
    "model.add(Cropping2D(cropping=((75, 25), (0, 0))))\n",
    "\n",
    "model.add(Conv2D(24,5, activation='elu'))\n",
    "model.add(MaxPooling2D()) #(2,2) pool with no stride, valid padding\n",
    "\n",
    "model.add(Conv2D(36,5, activation='elu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(48,5, activation='elu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64,3, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(511, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(127, activation='relu'))\n",
    "model.add(Dense(31, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
